{"metadata":{"title":"Advanced MaxEnt \/ POS Tagging \/ Parsing Intro","open_time":"2012-04-07 1100","soft_close_time":"2012-04-24 2359","hard_close_time":"2012-05-22 2359","duration":"0","retry_delay":"10","maximum_submissions":"5","modified_time":"1336578560149","parameters":{"show_explanations":{"question":"after_hard_close_time","option":"before_soft_close_time","score":"before_soft_close_time"}},"maximum_score":"5"},"preamble":{},"data":{"question_groups":{"question_group":[{"@attributes":{"select":"1"},"preamble":{},"question":[{"@attributes":{"id":"cd9085a882a058faec3b0b8d4a9260ad","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"Suppose we build a maxent model for part of speech tagging a word ($$x$$), over a set of just $$3$$ parts of speech ($$y$$): $$Noun$$, $$Verb$$, and $$Other$$.  Our model has just one feature:<br \/>\n<pre>\nf(x,y) = [x=\"make\" & y=\"Verb\"]\n<\/pre>\nOur training data consists of $$5$$ observations:<br \/>\n<br \/>\n<pre>\n[x=\"make\" & y=\"Verb\"]\n[x=\"make\" & y=\"Verb\"]\n[x=\"make\" & y=\"Verb\"]\n[x=\"make\" & y=\"Verb\"]\n[x=\"make\" & y=\"Noun\"]\n<\/pre>\n<br \/>\nThe maxent model will be trained in the usual way to give the feature $$f$$ a weight $$\\lambda$$, so that the model expectation for the feature matches its empirical expectation.<br \/>\n<br \/>\nThe weight of the feature will be $$\\log X$$ (natural log).<br \/>\n<br \/>\nWhat is $$X$$?","explanation":"The empirical expectation of $$f$$ is $$4$$ from $$5$$ identical observed data $$x$$.  So $$P(Verb|make) = 0.8$$.<br \/>\n<br \/>\n$$P(Verb|make) = 0.8 = e^\\lambda\/(e^\\lambda + e^0 + e^0) = e^\\lambda\/(e^\\lambda + 2)$$<br \/>\n<br \/>\nSo:<br\/>\n<br \/>\n$$0.8[e^\\lambda + 2] = e^\\lambda$$<br \/>\n$$1.6 = 0.2e^\\lambda$$<br \/>\n$$8 = e^\\lambda$$<br \/>\n$$\\lambda = \\log 8$$<br \/>","option_groups":{"@attributes":{"randomize":"true"},"option_group":[{"@attributes":{"select":"all"},"option":{"@attributes":{"id":"56efeba2398a301f231f4624f9fadf5d","selected_score":"1","unselected_score":"0"},"text":"$$8$$","explanation":"Correct!"}},{"@attributes":{"select":"3"},"option":[{"@attributes":{"id":"27289cca724eca79ed7592f9409778f5","selected_score":"0","unselected_score":"0"},"text":"$$3$$","explanation":"Incorrect."},{"@attributes":{"id":"8ae2dee191f00a041e61f3b8426d75e0","selected_score":"0","unselected_score":"0"},"text":"$$4\/5$$","explanation":"Incorrect.<br \/>\nThat is the probability $$P(Verb|make)$$, which is not the same as the feature's weight."},{"@attributes":{"id":"6fc660f2f90626693c84d3116fafb023","selected_score":"0","unselected_score":"0"},"text":"$$1$$","explanation":"Incorrect."},{"@attributes":{"id":"e087ff4547ce9d2785f029d594f220cf","selected_score":"0","unselected_score":"0"},"text":"$$4$$","explanation":"Incorrect.\nJust because the feature shows up $$4$$ times in the training set does not mean it gets the weight $$\\log 4$$."},{"@attributes":{"id":"a2394cc372d61ca91583ed030946f81b","selected_score":"0","unselected_score":"0"},"text":"$$5\/4$$","explanation":"Incorrect."}]}]}}},{"@attributes":{"id":"b385aa9f52cf5b1c9a5310c18f3ad5af","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"Suppose we build a maxent model for part of speech tagging a word ($$x$$), over a set of just $$3$$ parts of speech ($$y$$): $$Noun$$, $$Verb$$, and $$Other$$.  Our model has just one feature:<br \/>\n<pre>\nf(x,y) = [x=\"breeze\" & y=\"Noun\"]\n<\/pre>\nOur training data consists of $$5$$ observations:<br \/>\n<br \/>\n<pre>\n[x=\"breeze\" & y=\"Verb\"]\n[x=\"breeze\" & y=\"Verb\"]\n[x=\"breeze\" & y=\"Verb\"]\n[x=\"breeze\" & y=\"Noun\"]\n[x=\"breeze\" & y=\"Noun\"]\n<\/pre>\n<br \/>\nThe maxent model will be trained in the usual way to give the feature $$f$$ a weight $$\\lambda$$, so that the model expectation for the feature matches its empirical expectation.<br \/>\n<br \/>\nThe weight of the feature will be $$\\log X$$ (natural log).<br \/>\n<br \/>\nWhat is $$X$$?","explanation":"The empirical expectation of $$f$$ is $$2$$ from $$5$$ identical observed data $$x$$.  So $$P(Noun|breeze) = 0.4$$.<br \/>\n<br \/>\n$$P(Noun|breeze) = 0.4 = e^\\lambda\/(e^\\lambda + e^0 + e^0) = e^\\lambda\/(e^\\lambda + 2)$$<br \/>\n<br \/>\nSo:<br\/>\n<br \/>\n$$0.4[e^\\lambda + 2] = e^\\lambda$$<br \/>\n$$0.8 = 0.6e^\\lambda$$<br \/>\n$$4\/3 = e^\\lambda$$<br \/>\n$$\\lambda = \\log (4\/3)$$<br \/>","option_groups":{"@attributes":{"randomize":"true"},"option_group":[{"@attributes":{"select":"all"},"option":{"@attributes":{"id":"5d0a6597e6a0db41bb4799313ffb035e","selected_score":"1","unselected_score":"0"},"text":"$$4\/3$$","explanation":"Correct!"}},{"@attributes":{"select":"3"},"option":[{"@attributes":{"id":"9d969f8e17742970dac6f6307f50b515","selected_score":"0","unselected_score":"0"},"text":"$$3$$","explanation":"Incorrect."},{"@attributes":{"id":"75aacb9417b53161f1af653e6cdf7781","selected_score":"0","unselected_score":"0"},"text":"$$2\/5$$","explanation":"Incorrect.<br \/>\nThat is the probability $$P(Noun|breeze)$$, which is not the same as the feature's weight"},{"@attributes":{"id":"720050860b1a80b88b05e9304e48a67c","selected_score":"0","unselected_score":"0"},"text":"$$3\/5$$","explanation":"Incorrect."},{"@attributes":{"id":"6f6a6e15c286583d41d1c50f382e194d","selected_score":"0","unselected_score":"0"},"text":"$$15$$","explanation":"Incorrect."},{"@attributes":{"id":"860b66e8d9c1b8eb497e4f91dcc3ba7c","selected_score":"0","unselected_score":"0"},"text":"$$2$$","explanation":"Incorrect.\nJust because the feature shows up $$2$$ times in the training set does not mean it gets the weight $$\\log 2$$."}]}]}}}]},{"@attributes":{"select":"1"},"preamble":{},"question":[{"@attributes":{"id":"52eec3c0e4f54ac11d8e8f3b59c6f5ff","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"Suppose we build a maxent model for part of speech tagging a word ($$x$$), over a set of just $$3$$ parts of speech ($$y$$): $$Noun$$, $$Verb$$, and $$Other$$.  Our model has just one feature:<br \/>\n<pre>\nf(x,y) = [x=\"make\" & y=\"Verb\"]\n<\/pre>\nOur training data consists of $$5$$ observations:<br \/>\n<br \/>\n<pre>\n[x=\"make\" & y=\"Verb\"]\n[x=\"make\" & y=\"Verb\"]\n[x=\"make\" & y=\"Verb\"]\n[x=\"make\" & y=\"Verb\"]\n[x=\"make\" & y=\"Noun\"]\n<\/pre>\n<br \/>\nThe maxent model will be trained in the usual way to give the feature $$f$$ a weight $$\\lambda$$, so that the model expectation for the feature matches its empirical expectation.<br \/>\n<br \/>\n What probability will the model give to $$P(Noun | make)$$?","explanation":"$$P(Verb|make) = 0.8$$, and the rest is uniform, so $$0.1$$ for each other class.<br \/>\nYou can also confirm this from:<br \/>\n$$P(Noun | make) = P(Other | make) = e^0\/(e^{\\log 8} + e^0 + e^0) = 1\/(8 + 1 + 1) = 1\/10$$","option_groups":{"@attributes":{"randomize":"true"},"option_group":[{"@attributes":{"select":"all"},"option":{"@attributes":{"id":"db0bcfdc6086216eb78a4ac173d2f746","selected_score":"1","unselected_score":"0"},"text":"$$1\/10$$","explanation":"Correct!"}},{"@attributes":{"select":"3"},"option":[{"@attributes":{"id":"d3c9f0dfa25126289c1f2b7b4d203a5b","selected_score":"0","unselected_score":"0"},"text":"$$1\/5$$","explanation":"Incorrect."},{"@attributes":{"id":"f25010f455999be911aeeab8cf04d921","selected_score":"0","unselected_score":"0"},"text":"$$1\/2$$","explanation":"Incorrect."},{"@attributes":{"id":"dc826c8bda342564bbcceacd29f99bf0","selected_score":"0","unselected_score":"0"},"text":"$$0$$","explanation":"Incorrect."},{"@attributes":{"id":"a00451e7643fe599ebafc238d3105ca6","selected_score":"0","unselected_score":"0"},"text":"$$1\/9$$","explanation":"Incorrect."},{"@attributes":{"id":"1f956aa51ba047e2b3f98832083fc132","selected_score":"0","unselected_score":"0"},"text":"$$1\/18$$","explanation":"Incorrect."}]}]}}},{"@attributes":{"id":"5e0123350581556dfe93431fde4fb4c9","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"Suppose we build a maxent model for part of speech tagging a word ($$x$$), over a set of just $$3$$ parts of speech ($$y$$): $$Noun$$, $$Verb$$, and $$Other$$.  Our model has just one feature:<br \/>\n<pre>\nf(x,y) = [x=\"breeze\" & y=\"Noun\"]\n<\/pre>\nOur training data consists of $$5$$ observations:<br \/>\n<br \/>\n<pre>\n[x=\"breeze\" & y=\"Verb\"]\n[x=\"breeze\" & y=\"Verb\"]\n[x=\"breeze\" & y=\"Verb\"]\n[x=\"breeze\" & y=\"Noun\"]\n[x=\"breeze\" & y=\"Noun\"]\n<\/pre>\n<br \/>\nThe maxent model will be trained in the usual way to give the feature $$f$$ a weight $$\\lambda$$, so that the model expectation for the feature matches its empirical expectation.<br \/>\n<br \/>\n What probability will the model give to $$P(Other | breeze)$$?","explanation":"$$P(Noun|breeze) = 0.4$$, and the rest is uniform, so $$0.3$$ for each other class.<br \/>\nYou can also confirm this from:<br \/>\n$$P(Noun | make) = P(Other | make) = e^0\/(e^{\\log (4\/3)} + e^0 + e^0) = 1\/(4\/3 + 1 + 1) = 3\/10$$","option_groups":{"@attributes":{"randomize":"true"},"option_group":[{"@attributes":{"select":"all"},"option":{"@attributes":{"id":"737871a432d98c19d4d892648430b441","selected_score":"1","unselected_score":"0"},"text":"$$3\/10$$","explanation":"Correct!"}},{"@attributes":{"select":"3"},"option":[{"@attributes":{"id":"2e1235d29bf5b055bd857abc347b92dc","selected_score":"0","unselected_score":"0"},"text":"$$0$$","explanation":"Incorrect.<br \/>\nEven though <code>[x=\"breeze\" & y=\"Other\"]<\/code> does not occur in the training data, the probability $$P(Other|breeze)$$ is nonzero."},{"@attributes":{"id":"dc34f4f1b5b52fcafc47a3c32b1f56cd","selected_score":"0","unselected_score":"0"},"text":"$$3\/5$$","explanation":"Incorrect."},{"@attributes":{"id":"11ae773f8e0765dfc4b083fb4d0eba9e","selected_score":"0","unselected_score":"0"},"text":"$$1\/10$$","explanation":"Incorrect."},{"@attributes":{"id":"60719deb2e7d42f5dbf8fc8125372b7c","selected_score":"0","unselected_score":"0"},"text":"$$3\/14$$","explanation":"Incorrect."},{"@attributes":{"id":"fe0ca8bb038b03aa799ca2ae8ef5aea5","selected_score":"0","unselected_score":"0"},"text":"$$3\/7$$","explanation":"Incorrect."}]}]}}}]},{"@attributes":{"select":"1"},"preamble":{},"question":[{"@attributes":{"id":"f9e3b0f366e371478b46125df64cacd7","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"Suppose we build a maxent model for part of speech tagging a word ($$x$$), over a set of just $$3$$ parts of speech ($$y$$): $$Noun$$, $$Verb$$, and $$Other$$.  Our model has just one feature:<br \/>\n<pre>\nf(x,y) = [x=\"make\" & y=\"Verb\"]\n<\/pre>\nOur training data consists of $$5$$ observations:<br \/>\n<br \/>\n<pre>\n[x=\"make\" & y=\"Verb\"]\n[x=\"make\" & y=\"Verb\"]\n[x=\"make\" & y=\"Verb\"]\n[x=\"make\" & y=\"Verb\"]\n[x=\"make\" & y=\"Noun\"]\n<\/pre>\n<br \/>\nThe maxent model will be trained in the usual way to give the feature $$f$$ a weight $$\\lambda$$, so that the model expectation for the feature matches its empirical expectation. Suppose we now put gaussian regularization into the same model over the same data with $$\\sigma = 1$$.<br \/>\n<br \/>\nThe optimal weight of the feature will still be of the form $$\\log X$$ (natural log).  What is $$X$$?<br \/>","explanation":"We have in terms of expectations that:<br \/>\n<br \/>\n$$4 - predicted\\_count(\\lambda) - \\sigma = 0$$<br \/>\nI.e., $$4 - 5[e^\\lambda\/(e^\\lambda + 2)] - 1 = 0$$<br \/>\n<br \/>\nSo,<br \/>\n<br \/>\n$$3\/5 = e^\\lambda\/(e^\\lambda + 2)$$<br \/>\n$$3\/5e^\\lambda + 6\/5 = e^\\lambda$$<br \/>\n$$6\/5 = 2\/5e^\\lambda$$<br \/>\n$$3 = e^\\lambda$$<br \/>\n$$\\lambda = \\log 3$$","option_groups":{"@attributes":{"randomize":"true"},"option_group":[{"@attributes":{"select":"all"},"option":{"@attributes":{"id":"5898f3cca8041d118eab7fe0b936d253","selected_score":"1","unselected_score":"0"},"text":"$$3$$","explanation":"Correct!"}},{"@attributes":{"select":"3"},"option":[{"@attributes":{"id":"a1e23d72e21cd7b2615f1050c3bf54fa","selected_score":"1","unselected_score":"0"},"text":"$$4$$","explanation":"Incorrect."},{"@attributes":{"id":"76818ebd739fefe15a132d26c15b64ab","selected_score":"1","unselected_score":"0"},"text":"$$7$$","explanation":"Incorrect."},{"@attributes":{"id":"9b2d4f9f97fa78d61bd1454d86223ed1","selected_score":"1","unselected_score":"0"},"text":"$$9$$","explanation":"Incorrect."},{"@attributes":{"id":"cb95673cdc41153176c40aeba3d6614f","selected_score":"1","unselected_score":"0"},"text":"$$5\/8$$","explanation":"Incorrect."},{"@attributes":{"id":"7d6d3ad7cf660223b57d23e71b4a6f71","selected_score":"1","unselected_score":"0"},"text":"$$3\/4$$","explanation":"Incorrect."}]}]}}},{"@attributes":{"id":"96ab08207532c69956109fb3653281c2","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"Suppose we build a maxent model for part of speech tagging a word ($$x$$), over a set of just $$3$$ parts of speech ($$y$$): $$Noun$$, $$Verb$$, and $$Other$$.  Our model has just one feature:<br \/>\n<pre>\nf(x,y) = [x=\"breeze\" & y=\"Noun\"]\n<\/pre>\nOur training data consists of $$5$$ observations:<br \/>\n<br \/>\n<pre>\n[x=\"breeze\" & y=\"Verb\"]\n[x=\"breeze\" & y=\"Verb\"]\n[x=\"breeze\" & y=\"Verb\"]\n[x=\"breeze\" & y=\"Noun\"]\n[x=\"breeze\" & y=\"Noun\"]\n<\/pre>\n<br \/>\nThe maxent model will be trained in the usual way to give the feature $$f$$ a weight $$\\lambda$$, so that the model expectation for the feature matches its empirical expectation. Suppose we now put gaussian regularization into the same model over the same data with $$\\sigma = 1$$.<br \/>\n<br \/>\nThe optimal weight of the feature will still be of the form $$\\log X$$ (natural log).  What is $$X$$?<br \/>","explanation":"We have in terms of expectations that:<br \/>\n<br \/>\n$$2 - predicted\\_count(\\lambda) - \\sigma = 0$$<br \/>\nI.e., $$2 - 5[e^\\lambda\/(e^\\lambda + 2)] - 1 = 0$$<br \/>\n<br \/>\nSo,<br \/>\n<br \/>\n$$1\/5 = e^\\lambda\/(e^\\lambda + 2)$$<br \/>\n$$1\/5e^\\lambda + 2\/5 = e^\\lambda$$<br \/>\n$$2\/5 = 4\/5e^\\lambda$$<br \/>\n$$1\/2 = e^\\lambda$$<br \/>\n$$\\lambda = \\log (1\/2)$$","option_groups":{"@attributes":{"randomize":"true"},"option_group":[{"@attributes":{"select":"all"},"option":{"@attributes":{"id":"098e35d240b6bba4f27d8e9cb81b6059","selected_score":"1","unselected_score":"0"},"text":"$$1\/2$$","explanation":"Correct!"}},{"@attributes":{"select":"3"},"option":[{"@attributes":{"id":"25e803c33868f322d979ba72ead1d7df","selected_score":"1","unselected_score":"0"},"text":"$$1\/3$$","explanation":"Incorrect."},{"@attributes":{"id":"1e09fd1f5d0cd4f7783e18de8379d2d7","selected_score":"1","unselected_score":"0"},"text":"$$1$$","explanation":"Incorrect."},{"@attributes":{"id":"bd9d3b0a1940e0428b155c453a2e1fc3","selected_score":"1","unselected_score":"0"},"text":"$$3$$","explanation":"Incorrect."},{"@attributes":{"id":"8fdd1a3459fe4aceb622d63563e2b7a1","selected_score":"1","unselected_score":"0"},"text":"$$1\/4$$","explanation":"Incorrect."},{"@attributes":{"id":"8be70e64b048b8fec1e07e568dbaa184","selected_score":"1","unselected_score":"0"},"text":"$$3\/2$$","explanation":"Incorrect."}]}]}}}]},{"@attributes":{"select":"1"},"preamble":{},"question":[{"@attributes":{"id":"ff51e37101430881cb6ede67675954d5","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"Do the part-of-speech tagging by hand for the following sentence using <a href=http:\/\/www.ling.upenn.edu\/courses\/Fall_2003\/ling001\/penn_treebank_pos.html>Penn Treebank POS tags<\/a>:<br \/>\n<br \/>\nStanford\/? and\/? Open\/? University\/? have\/? been\/? downloaded\/? 50\/? million\/? times\/? on\/? iTunes\/? !\/?","explanation":{},"option_groups":{"@attributes":{"randomize":"true"},"option_group":[{"@attributes":{"select":"all"},"option":{"@attributes":{"id":"ea49d81d7a5acffcb600c54dca461c5f","selected_score":"1","unselected_score":"0"},"text":"Stanford\/NNP and\/CC Open\/NNP University\/NNP have\/VBP been\/VBN downloaded\/VBN 50\/CD million\/CD times\/NNS on\/IN iTunes\/NNP !\/.","explanation":"Correct!"}},{"@attributes":{"select":"3"},"option":[{"@attributes":{"id":"a497608a23a6b394c95e7a823c2b70d6","selected_score":"0","unselected_score":"0"},"text":"Stanford\/NNP and\/CC Open\/NNP University\/NNP have\/VBP been\/VBN downloaded\/VBN 50\/SYM million\/CD times\/NNS on\/IN iTunes\/NNS !\/.","explanation":"Incorrect.<br \/>\n\"50\" is a cardinal number (CD).<br \/>\n\"iTunes\" is a singular proper noun (NNP)."},{"@attributes":{"id":"21ab010e596eb219ea036c0edd4c1228","selected_score":"0","unselected_score":"0"},"text":"Stanford\/NNP and\/CC Open\/JJ University\/NN have\/VBP been\/VBN downloaded\/VBN 50\/CD million\/CD times\/NNS on\/IN iTunes\/NNP !\/.","explanation":"Incorrect.<br\/>\n\"Open University\" is a singular proper noun, so both should be labeled NNP."},{"@attributes":{"id":"287bf95aeef769c227a0c015d238ff2b","selected_score":"0","unselected_score":"0"},"text":"Stanford\/NNP and\/CC Open\/NNP University\/NNP have\/VB been\/VBN downloaded\/VBN 50\/CD million\/CD times\/NNS on\/JJ iTunes\/NNS !\/.","explanation":"Incorrect.<br\/>\n\"have\" is a non-3rd-person-singular present verb (VBP).<br \/>\n\"on\" is preposition (IN).<br \/>\n\"iTunes\" is a singular proper noun (NNP)."},{"@attributes":{"id":"73ea748f2ae8c7bf8196096e54e55b69","selected_score":"0","unselected_score":"0"},"text":"Stanford\/NNP and\/IN Open\/JJ University\/NNP have\/VBP been\/VBN downloaded\/VBN 50\/CD million\/CD times\/NNS on\/IN iTunes\/NNP !\/.","explanation":"Incorrect.\n\"Open University\" is a singular proper noun, so both should be labeled NNP.\n\"and\" is neither a preposition nor subordinating conjunction -- it is a coordinating conjunction (CC)."}]}]}}},{"@attributes":{"id":"a23a2605f9b4b53469ceaf3515fb1952","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"Do the part-of-speech tagging by hand for the following sentence using <a href=http:\/\/www.ling.upenn.edu\/courses\/Fall_2003\/ling001\/penn_treebank_pos.html>Penn Treebank POS tags<\/a>:<br \/>\n<br \/>\nKnowing\/? a\/? word\/? 's\/? part\/? of\/? speech\/? can\/? help\/? in\/? many\/? NLP\/? tasks\/? .\/?","explanation":{},"option_groups":{"@attributes":{"randomize":"true"},"option_group":[{"@attributes":{"select":"all"},"option":{"@attributes":{"id":"770ce9dce7c2654981d94dafb6f54b12","selected_score":"1","unselected_score":"0"},"text":"Knowing\/VBG a\/DT word\/NN 's\/POS part\/NN of\/IN speech\/NN can\/MD help\/VB in\/IN many\/JJ NLP\/NNP tasks\/NNS .\/.","explanation":"Correct!"}},{"@attributes":{"select":"3"},"option":[{"@attributes":{"id":"8b8edabc842fd45f8a83984fa490221c","selected_score":"0","unselected_score":"0"},"text":"Knowing\/VB a\/DT word\/NN 's\/POS part\/NN of\/IN speech\/NN can\/MD help\/VB in\/IN many\/CD NLP\/NNP tasks\/NNS .\/.","explanation":"Incorrect.<br \/>\n\"Knowing\" is a gerund (VBG).<br \/>\n\"man\" is an adjective (JJ), not a cardinal number."},{"@attributes":{"id":"601974f5bdd1369c0483e7ea53922b40","selected_score":"0","unselected_score":"0"},"text":"Knowing\/VBG a\/DT word\/NNS 's\/NNS part\/NN of\/IN speech\/NN can\/MD help\/VB in\/IN many\/JJ NLP\/NNP tasks\/NNS .\/.","explanation":"Incorrect.<br \/>\n\"word\" is a singular noun (NN) and \"'s\" is a possessive ending (POS) -- \"word's\" does <em>not<\/em> make up a plural noun."},{"@attributes":{"id":"afcecd0210a7b848a7c2d622df60aec5","selected_score":"0","unselected_score":"0"},"text":"Knowing\/VB a\/IN word\/NN 's\/POS part\/NN of\/IN speech\/NN can\/MD help\/VB in\/IN many\/CD NLP\/NNP tasks\/NNS .\/.","explanation":"Incorrect.<br \/>\n\"Knowing\" is a gerund (VBG).<br \/>\n\"a\" is a determiner (DT), not a preposition.<br \/>\n\"many\" is an adjective (JJ), not a cardinal number."},{"@attributes":{"id":"b1dda42ca3fd99f34570c30955968716","selected_score":"0","unselected_score":"0"},"text":"Knowing\/VBG a\/DT word\/NN 's\/POS part\/NN of\/IN speech\/NN can\/VB help\/VB in\/IN many\/CD NLP\/NNP tasks\/NNS .\/.","explanation":"Incorrect.<br \/>\n\"can\" is a modifier (MD), not a verb.<br \/>\n\"many\" is an adjective (JJ), not a cardinal number."}]}]}}}]},{"@attributes":{"select":"1"},"preamble":{},"question":[{"@attributes":{"id":"64232313cea55587aa8ca22ef1040b0c","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"Which of the given bracket groups is a constituent in the following sentence?<br \/>\n<br \/>\nSentence: <em>The air conditioning pouring out from the shops beckoned the passers-by to stay a while and cool off.<\/em><br \/>\n<br \/>\n[ [The air conditioning] pouring] [ out [from the shops] ] [ beckoned [the passers-by] ] to [stay a while and cool off].","explanation":{},"option_groups":{"@attributes":{"randomize":"true"},"option_group":[{"@attributes":{"select":"1"},"option":[{"@attributes":{"id":"8e61fbfc22370e5913288535ed433fb2","selected_score":"1","unselected_score":"0"},"text":"The air conditioning pouring","explanation":"Correct!"},{"@attributes":{"id":"038d22540450aa3c9a8afd07f4d24dad","selected_score":"1","unselected_score":"0"},"text":"out from the shops","explanation":"Correct!"},{"@attributes":{"id":"5d23fc278c46fa7b90ef5875a0d21bc9","selected_score":"1","unselected_score":"0"},"text":"beckoned the passers-by","explanation":"Correct!"}]},{"@attributes":{"select":"3"},"option":[{"@attributes":{"id":"15b5f9148f226b93c3c76e51ecaf7ce2","selected_score":"0","unselected_score":"0"},"text":"the shops beckoned","explanation":"Incorrect.<br \/>\nThe phrase does not fully occupy a bracketing."},{"@attributes":{"id":"9a1d43f192f9d63f743b1e016fadae97","selected_score":"0","unselected_score":"0"},"text":"beckoned the passers-by to stay a while","explanation":"Incorrect.<br \/>\nThe phrase does not fully occupy a bracketing."},{"@attributes":{"id":"7a2e1565ee2d63da10396c82f6732e28","selected_score":"0","unselected_score":"0"},"text":"pouring","explanation":"Incorrect.<br \/>\nThe phrase does not fully occupy a bracketing."},{"@attributes":{"id":"a3d4da0544c3f086fc5d5974c640dfca","selected_score":"0","unselected_score":"0"},"text":"The air conditioning pouring out","explanation":"Incorrect.<br \/>\nThe phrase does not fully occupy a bracketing."},{"@attributes":{"id":"894e7f60d6962aae9f55ab4f5796be5f","selected_score":"0","unselected_score":"0"},"text":"the shops","explanation":"Incorrect.<br \/>\nThe phrase does not fully occupy a bracketing."}]}]}}},{"@attributes":{"id":"c8e5a47d24f6c8cc7f525d30ba2fbee4","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"Which of the given bracket groups is a constituent in the following sentence?<br \/>\n<br \/>\nSentence: <em>When she was younger she would play outside with her friends until the bell rang for dinner.<\/em><br \/>\n<br \/>\n[When she was younger] [ [ she would play] outside ] [with her friends] [ [until the bell rang ] for dinner].","explanation":{},"option_groups":{"@attributes":{"randomize":"true"},"option_group":[{"@attributes":{"select":"1"},"option":[{"@attributes":{"id":"9349bc958c8bea1a718209842c69db9c","selected_score":"1","unselected_score":"0"},"text":"until the bell rang for dinner","explanation":"Correct!"},{"@attributes":{"id":"a4a903d2609be2d96c0ce28a0f743200","selected_score":"1","unselected_score":"0"},"text":"she would play outside","explanation":"Correct!"},{"@attributes":{"id":"76000a7142e4da5586964f3207ed3d6a","selected_score":"1","unselected_score":"0"},"text":"when she was younger","explanation":"Correct!"}]},{"@attributes":{"select":"3"},"option":[{"@attributes":{"id":"a8e5f1b3f560acc4702190543e86afd1","selected_score":"0","unselected_score":"0"},"text":"the bell rang for dinner","explanation":"Incorrect.<br \/>\nThe phrase does not fully occupy a bracketing."},{"@attributes":{"id":"92390e2dae3a1e673d2ddfadf6ac7e03","selected_score":"0","unselected_score":"0"},"text":"play outside","explanation":"Incorrect.<br \/>\nThe phrase does not fully occupy a bracketing."},{"@attributes":{"id":"4daa7456e2ded6e3f63804226fd8fc8e","selected_score":"0","unselected_score":"0"},"text":"outside with her friends","explanation":"Incorrect.<br \/>\nThe phrase does not fully occupy a bracketing."},{"@attributes":{"id":"0d3922ecd9915c94f5653dea57de75d3","selected_score":"0","unselected_score":"0"},"text":"she was younger","explanation":"Incorrect.<br \/>\nThe phrase does not fully occupy a bracketing."}]}]}}}]}]}}}