<quiz>
  <metadata>
    <title>Lexical Semantics and Question Answering</title>
    <open_time>2012-04-27 0001</open_time>
    <soft_close_time>2012-05-23 2359</soft_close_time>
    <hard_close_time>2012-05-23 2359</hard_close_time>
    <duration>0</duration>
    <retry_delay>10</retry_delay>
    <maximum_submissions>6</maximum_submissions>
    <modified_time>1337741809355</modified_time>
    <parameters>
      <show_explanations>
        <question>after_hard_close_time</question>
        <option>before_soft_close_time</option>
        <score>before_soft_close_time</score>
      </show_explanations>
    </parameters>
    <maximum_score>5</maximum_score>
  </metadata>
  <preamble><![CDATA[]]></preamble>
  <data>
    <question_groups>
      <question_group select="1">
        <preamble><![CDATA[]]></preamble>
        <question id="88a53bf7c453e4977c02869d060e40a5" type="GS_Short_Answer_Question_Simple">
          <metadata>
            <parameters>
              <rescale_score>1</rescale_score>
              <type>numeric</type>
            </parameters>
          </metadata>
          <data>
            <text><![CDATA[Assume we have a corpus of 1000 words and the following WordNet Hierarchy: <br/>

<img src="images/SemanticsQAExercise/Information_Content.png" alt="Node A has children B, C and D. Node B has children E and F. Node C has a child G. Node D has children H and I. Node E has children J and K. Node K has children O and P. Node H has children L, M, and N." height="300" width="650" />

<br/>Now assume we collect the following count data for each of the words:
<br/><br/>
J = 100 <br/>
O = 100 <br/>
P = 100 <br/>
F = 100 <br/>
G = 100 <br/>
L = 100 <br/>
M = 100 <br/>
N = 100 <br/>
I = 200 <br/>

<br/><br/>


Assuming that all other words do not appear in the corpus, what is $$\text{sim}_\text{resnick}(J, P)$$? Round your answer to two decimal places (e.g. 0.35, 0.60, 1.43) and use natural log in your calculation.]]></text>
            <explanation><![CDATA[We can solve this problem by first taking the lowest common subsumer of the two words. We can calculate the probability of that lowest common subsumer by summing up the counts of words in the subtree rooted at the lowest common subsumer (which in this case is simply summing over all the leaves) and dividing that number by 1000, the number of words in the corpus. We then take the negative log of that probability to obtain our answer.]]></explanation>
            <option_groups randomize="true">
              <option_group select="all">
                <option id="d42cbe195f9acbe0936a81266e2a626f" selected_score="1" unselected_score="0">
                  <text><![CDATA[[1.20,1.21]]]></text>
                  <explanation><![CDATA[]]></explanation>
                </option>
                <option id="4e184e6752d0f765c3016b4e0c22a536" selected_score="0" unselected_score="0">
                  <text><![CDATA[[-999999,1.199999]]]></text>
                  <explanation><![CDATA[Observe that there are no counts for internal nodes. Thus we can calculate the probability of any node by only examining the counts of the leaves of the subtree rooted at that node.]]></explanation>
                </option>
                <option id="ef4525b808586a64f2caf0ada4cd5fd6" selected_score="0" unselected_score="0">
                  <text><![CDATA[[1.20000001,10000000]]]></text>
                  <explanation><![CDATA[Observe that there are no counts for internal nodes. Thus we can calculate the probability of any node by only examining the counts of the leaves of the subtree rooted at that node.]]></explanation>
                </option>
              </option_group>
            </option_groups>
          </data>
        </question>
        <question id="1564d90ed288af795493b884f4d70794" type="GS_Short_Answer_Question_Simple">
          <metadata>
            <parameters>
              <rescale_score>1</rescale_score>
              <type>numeric</type>
            </parameters>
          </metadata>
          <data>
            <text><![CDATA[Assume we have a corpus of 1000 words and the following WordNet Hierarchy: <br/>

<img src="images/SemanticsQAExercise/Information_Content.png" alt="Node A has children B, C and D. Node B has children E and F. Node C has a child G. Node D has children H and I. Node E has children J and K. Node K has children O and P. Node H has children L, M, and N." height="300" width="650" />

<br/>Now assume we collect the following count data for each of the words:
<br/><br/>
J = 100 <br/>
O = 100 <br/>
P = 100 <br/>
F = 100 <br/>
G = 100 <br/>
L = 100 <br/>
M = 100 <br/>
N = 100 <br/>
I = 200 <br/>

<br/><br/>


Assuming that all other words do not appear in the corpus, what is $$\text{sim}_\text{resnick}(N, L)$$? Round your answer to two decimal places (e.g. 0.35, 0.60, 1.43) and use natural log in your calculation.]]></text>
            <explanation><![CDATA[We can solve this problem by first taking the lowest common subsumer of the two words. We can calculate the probability of that lowest common subsumer by summing up the counts of words in the subtree rooted at the lowest common subsumer (which in this case is simply summing over all the leaves) and dividing that number by 1000, the number of words in the corpus. We then take the negative log of that probability to obtain our answer.]]></explanation>
            <option_groups randomize="true">
              <option_group select="all">
                <option id="2e813ccf3493f21634d2f37329e605f4" selected_score="1" unselected_score="0">
                  <text><![CDATA[[1.20,1.21]]]></text>
                  <explanation><![CDATA[]]></explanation>
                </option>
                <option id="328cdf7d9b52d2c00f5057d49463d60a" selected_score="0" unselected_score="0">
                  <text><![CDATA[[-999999999,1.199999]]]></text>
                  <explanation><![CDATA[Observe that there are no counts for internal nodes. Thus we can calculate the probability of any node by only examining the counts of the leaves of the subtree rooted at that node.]]></explanation>
                </option>
                <option id="e99ab656aa8365b070edab85ea84384d" selected_score="0" unselected_score="0">
                  <text><![CDATA[[1.20000001,10000000]]]></text>
                  <explanation><![CDATA[Observe that there are no counts for internal nodes. Thus we can calculate the probability of any node by only examining the counts of the leaves of the subtree rooted at that node.]]></explanation>
                </option>
              </option_group>
            </option_groups>
          </data>
        </question>
        <question id="7f356cd96535157759385f325ded8cc8" type="GS_Short_Answer_Question_Simple">
          <metadata>
            <parameters>
              <rescale_score>1</rescale_score>
              <type>numeric</type>
            </parameters>
          </metadata>
          <data>
            <text><![CDATA[Assume we have a corpus of 1000 words and the following WordNet Hierarchy: <br/>

<img src="images/SemanticsQAExercise/Information_Content.png" alt="Node A has children B, C and D. Node B has children E and F. Node C has a child G. Node D has children H and I. Node E has children J and K. Node K has children O and P. Node H has children L, M, and N." height="300" width="650" />

<br/>Now assume we collect the following count data for each of the words:
<br/><br/>
J = 200 <br/>
P = 200 <br/>
F = 100 <br/>
G = 50 <br/>
L = 50 <br/>
M = 100 <br/>
N = 100 <br/>
I = 200 <br/>

<br/><br/>


Assuming that all other words do not appear in the corpus, what is $$\text{sim}_\text{resnick}(F, E)$$? Round your answer to two decimal places (e.g. 0.35, 0.60, 1.43) and use natural log in your calculation.]]></text>
            <explanation><![CDATA[We can solve this problem by first taking the lowest common subsumer of the two words. We can calculate the probability of that lowest common subsumer by summing up the counts of words in the subtree rooted at the lowest common subsumer (which in this case is simply summing over all the leaves) and dividing that number by 1000, the number of words in the corpus. We then take the negative log of that probability to obtain our answer.]]></explanation>
            <option_groups randomize="true">
              <option_group select="all">
                <option id="4c723852d64cd7e3766942a86882f635" selected_score="1" unselected_score="0">
                  <text><![CDATA[[0.69,0.79]]]></text>
                  <explanation><![CDATA[]]></explanation>
                </option>
                <option id="2a140baeb26c22a75d078accfe089016" selected_score="0" unselected_score="0">
                  <text><![CDATA[[0.7900000001,1000000000]]]></text>
                  <explanation><![CDATA[Observe that there are no counts for internal nodes. Thus we can calculate the probability of any node by only examining the counts of the leaves of the subtree rooted at that node.]]></explanation>
                </option>
                <option id="b5bbae0fbb15561a2fcaa6cadda71b16" selected_score="0" unselected_score="0">
                  <text><![CDATA[[-99999999,.68999999]]]></text>
                  <explanation><![CDATA[Observe that there are no counts for internal nodes. Thus we can calculate the probability of any node by only examining the counts of the leaves of the subtree rooted at that node.]]></explanation>
                </option>
              </option_group>
            </option_groups>
          </data>
        </question>
        <question id="6bea3154ca51bc569f6d76526678dbab" type="GS_Short_Answer_Question_Simple">
          <metadata>
            <parameters>
              <rescale_score>1</rescale_score>
              <type>numeric</type>
            </parameters>
          </metadata>
          <data>
            <text><![CDATA[Assume we have a corpus of 1000 words and the following WordNet Hierarchy: <br/>

<img src="images/SemanticsQAExercise/Information_Content.png" alt="Node A has children B, C and D. Node B has children E and F. Node C has a child G. Node D has children H and I. Node E has children J and K. Node K has children O and P. Node H has children L, M, and N." height="300" width="650" />

<br/>Now assume we collect the following count data for each of the words:
<br/><br/>
J = 200 <br/>
P = 200 <br/>
F = 100 <br/>
G = 50 <br/>
L = 50 <br/>
M = 100 <br/>
N = 100 <br/>
I = 200 <br/>

<br/><br/>


Assuming that all other words do not appear in the corpus, what is $$\text{sim}_\text{resnick}(M, I)$$? Round your answer to two decimal places (e.g. 0.35, 0.60, 1.43) and use natural log in your calculation.]]></text>
            <explanation><![CDATA[We can solve this problem by first taking the lowest common subsumer of the two words. We can calculate the probability of that lowest common subsumer by summing up the counts of words in the subtree rooted at the lowest common subsumer (which in this case is simply summing over all the leaves) and dividing that number by 1000, the number of words in the corpus. We then take the negative log of that probability to obtain our answer.]]></explanation>
            <option_groups randomize="true">
              <option_group select="all">
                <option id="3d74908f690c93f3287b77310211ee9a" selected_score="1" unselected_score="0">
                  <text><![CDATA[[0.79,0.80]]]></text>
                  <explanation><![CDATA[]]></explanation>
                </option>
                <option id="ad519b19773c4da1b5645c3b46d59e4e" selected_score="0" unselected_score="0">
                  <text><![CDATA[[0.800000001,100000000]]]></text>
                  <explanation><![CDATA[Observe that there are no counts for internal nodes. Thus we can calculate the probability of any node by only examining the counts of the leaves of the subtree rooted at that node.]]></explanation>
                </option>
                <option id="22e00be56ed8b6769056b034ed660f92" selected_score="0" unselected_score="0">
                  <text><![CDATA[[-999999999,0.789]]]></text>
                  <explanation><![CDATA[Observe that there are no counts for internal nodes. Thus we can calculate the probability of any node by only examining the counts of the leaves of the subtree rooted at that node.]]></explanation>
                </option>
              </option_group>
            </option_groups>
          </data>
        </question>
      </question_group>
      <question_group select="1">
        <preamble><![CDATA[Consider the following list of words and their hypernyms, which are listed in order from the word itself to the root of the WordNet hierarchy:
<br/><br/>
shoe, plate, shield, protection, covering, artifact, whole, object, physical entity, entity <br/>
shoe, footwear, covering, artifact, whole, object, physical entity, entity <br/>
<br/>
drive, propulsion, act, event, psychological feature, abstract entity, entity <br/>
drive, mechanism, device, instrumentality, artifact, whole, object, physical entity, entity <br/>
<br/>
disc, sound recording, recording, memory device, device, instrumentality, artifact, whole, object, physical entity, entity <br/>
disc, round shape, shape, attribute, abstract entity, entity <br/>
<br/>
chair, seat, furniture, furnishing, instrumentality, artifact, whole, object, physical entity, entity <br/>
chair, position, occupation, activity, act, event, psychological feature, abstract entity, entity <br/>
<br/>]]></preamble>
        <question id="4eb55f98fff40074b2f48f175c88606b" type="GS_Short_Answer_Question_Simple">
          <metadata>
            <parameters>
              <rescale_score>1</rescale_score>
              <type>numeric</type>
            </parameters>
          </metadata>
          <data>
            <text><![CDATA[Calculate wordsim(shoe, drive) and round your answer to two decimal places.]]></text>
            <explanation><![CDATA[Because there are two senses for each word, we must calculate the pairwise distance between four different pairs of senses. We then take the shortest of those path lengths and use that to compute the wordsim by taking the reciprocal of that number. We can calculate the path length between two senses by examining where along the list of each sense's hypernyms the two senses intersect.]]></explanation>
            <option_groups randomize="true">
              <option_group select="all">
                <option id="25d505e4b5ace5c65d748e88ab134e81" selected_score="1" unselected_score="0">
                  <text><![CDATA[[0.12,0.13]]]></text>
                  <explanation><![CDATA[]]></explanation>
                </option>
                <option id="d572f96affe0fb3fca64dd4a0167bdaf" selected_score="0" unselected_score="0">
                  <text><![CDATA[[-999999999,0.1199999999]]]></text>
                  <explanation><![CDATA[Remember that there are 4 possible pairwise path lengths you must compute.]]></explanation>
                </option>
                <option id="4b95d6abd703f1fb8859dca44133d558" selected_score="0" unselected_score="0">
                  <text><![CDATA[[0.130000001,9999999]]]></text>
                  <explanation><![CDATA[Remember that there are 4 possible pairwise path lengths you must compute.]]></explanation>
                </option>
              </option_group>
            </option_groups>
          </data>
        </question>
        <question id="cf67911cf04dd226f77e020d56bbc02f" type="GS_Short_Answer_Question_Simple">
          <metadata>
            <parameters>
              <rescale_score>1</rescale_score>
              <type>numeric</type>
            </parameters>
          </metadata>
          <data>
            <text><![CDATA[Calculate wordsim(shoe, disc) and round your answer to two decimal places.]]></text>
            <explanation><![CDATA[Because there are two senses for each word, we must calculate the pairwise distance between four different pairs of senses. We then take the shortest of those path lengths and use that to compute the wordsim by taking the reciprocal of that number. We can calculate the path length between two senses by examining where along the list of each sense's hypernyms the two senses intersect.]]></explanation>
            <option_groups randomize="true">
              <option_group select="all">
                <option id="1de633a38339e350b13f82e709b9b810" selected_score="1" unselected_score="0">
                  <text><![CDATA[[0.09,0.11]]]></text>
                  <explanation><![CDATA[]]></explanation>
                </option>
                <option id="7e0ee7084c23b91fbcb3622014c37d3b" selected_score="0" unselected_score="0">
                  <text><![CDATA[[-9999999,0.0899999999]]]></text>
                  <explanation><![CDATA[Remember that there are 4 possible pairwise path lengths you must compute.]]></explanation>
                </option>
                <option id="98dabaa9f426d5897d05be678a95106a" selected_score="0" unselected_score="0">
                  <text><![CDATA[[0.110000001,99999999]]]></text>
                  <explanation><![CDATA[Remember that there are 4 possible pairwise path lengths you must compute.]]></explanation>
                </option>
              </option_group>
            </option_groups>
          </data>
        </question>
        <question id="d4eff24e47c8e7ebcaa6fa730bd0e692" type="GS_Short_Answer_Question_Simple">
          <metadata>
            <parameters>
              <rescale_score>1</rescale_score>
              <type>numeric</type>
            </parameters>
          </metadata>
          <data>
            <text><![CDATA[Calculate wordsim(drive, chair) and round your answer to two decimal places.]]></text>
            <explanation><![CDATA[Because there are two senses for each word, we must calculate the pairwise distance between four different pairs of senses. We then take the shortest of those path lengths and use that to compute the wordsim by taking the reciprocal of that number. We can calculate the path length between two senses by examining where along the list of each sense's hypernyms the two senses intersect.]]></explanation>
            <option_groups randomize="true">
              <option_group select="all">
                <option id="54a670f13e844fc787e4ddc23211488c" selected_score="1" unselected_score="0">
                  <text><![CDATA[[0.14,0.15]]]></text>
                  <explanation><![CDATA[]]></explanation>
                </option>
                <option id="70cd0cae6da7b9d1693013a5a0165149" selected_score="0" unselected_score="0">
                  <text><![CDATA[[-9999999,0.13999999]]]></text>
                  <explanation><![CDATA[Remember that there are 4 possible pairwise path lengths you must compute.]]></explanation>
                </option>
                <option id="25499c975b66a9c749a7c50cdde7b075" selected_score="0" unselected_score="0">
                  <text><![CDATA[[0.1500000001,99999999]]]></text>
                  <explanation><![CDATA[Remember that there are 4 possible pairwise path lengths you must compute.]]></explanation>
                </option>
              </option_group>
            </option_groups>
          </data>
        </question>
        <question id="22bad7533d3a863f6e8496421b441ffc" type="GS_Short_Answer_Question_Simple">
          <metadata>
            <parameters>
              <rescale_score>1</rescale_score>
              <type>numeric</type>
            </parameters>
          </metadata>
          <data>
            <text><![CDATA[Calculate wordsim(disc, chair) and round your answer to two decimal places.]]></text>
            <explanation><![CDATA[Because there are two senses for each word, we must calculate the pairwise distance between four different pairs of senses. We then take the shortest of those path lengths and use that to compute the wordsim by taking the reciprocal of that number. We can calculate the path length between two senses by examining where along the list of each sense's hypernyms the two senses intersect.]]></explanation>
            <option_groups randomize="true">
              <option_group select="all">
                <option id="6d2476fa8f831d5fa8df9fc0b60fac63" selected_score="1" unselected_score="0">
                  <text><![CDATA[[0.095,0.1050]]]></text>
                  <explanation><![CDATA[]]></explanation>
                </option>
                <option id="9991b266d0e94cb2a6ebe31e7fd2360c" selected_score="0" unselected_score="0">
                  <text><![CDATA[[-9999999,0.094999999]]]></text>
                  <explanation><![CDATA[Remember that there are 4 possible pairwise path lengths you must compute.]]></explanation>
                </option>
                <option id="23c5b75073ea70c4d3db0fa47cb1f2b8" selected_score="0" unselected_score="0">
                  <text><![CDATA[[0.10500000001,9999999]]]></text>
                  <explanation><![CDATA[Remember that there are 4 possible pairwise path lengths you must compute.]]></explanation>
                </option>
              </option_group>
            </option_groups>
          </data>
        </question>
      </question_group>
      <question_group select="1">
        <preamble><![CDATA[]]></preamble>
        <question id="3887428989778a3506e57af644eae6d7" type="GS_Short_Answer_Question_Simple">
          <metadata>
            <parameters>
              <rescale_score>1</rescale_score>
              <type>numeric</type>
            </parameters>
          </metadata>
          <data>
            <text><![CDATA[Let's say we've calculated $$ppmi(\text{Stanford, University})$$, that is the positive pointwise mutual information for the word "Stanford" in the context of "University", and found that to be 2.3219. The particular context we are examining is one in which "University" was the next word following "Stanford", though for this problem, you don't need to be concerned with how the specific context is defined. Your professor now wants you to find how many of the sentences you examined contained the word "Stanford". Rather than running through the entire corpus and searching for the word "Stanford", you instead attempt to calculate this count using numbers you noted from before. 
<br/><br/>
You remember looking at a corpus of 100,000 sentences, and of those sentences, there was a 50% chance that you saw "Stanford" right before the word "University" in the sentence when a sentence contained "University". For the sake of simplicity, also assume that each sentence contained at most one instance of the word "Stanford" or "University". How many times did the word "Stanford" appear in your corpus? Assume that the ppmi was calculated using a log of base 2 and round your answer to the nearest integer. Also, if your integer involves more than three digits, please do not include commas in your response, (so 1,234 -> 1234).]]></text>
            <explanation><![CDATA[Using the formula for ppmi, we have that,
<br/><br/>
$$2.3219 = \frac{P(w | c) P(c)}{P(w)P(c)} = \frac{0.5}{x / 100000}$$
<br/><br/>
which we get from the fact that the $$P(c)$$s cancel out. Solving for the equation of $$x$$ gives us our solution of 10000.]]></explanation>
            <option_groups randomize="true">
              <option_group select="all">
                <option id="e178a07875e67163c76d1f01c6c6523f" selected_score="1" unselected_score="0">
                  <text><![CDATA[[9995,10005]]]></text>
                  <explanation><![CDATA[]]></explanation>
                </option>
                <option id="dd54e040d94be3287ec450e7bd143da0" selected_score="0" unselected_score="0">
                  <text><![CDATA[[-9999999,9994.99999]]]></text>
                  <explanation><![CDATA[Remember that $$P(x, y) = P(x | y) P(y)$$]]></explanation>
                </option>
                <option id="97a3d3275a1b36165e3e8d94f4683f2c" selected_score="0" unselected_score="0">
                  <text><![CDATA[[10005.000001,9999999]]]></text>
                  <explanation><![CDATA[Remember that $$P(x, y) = P(x | y) P(y)$$]]></explanation>
                </option>
              </option_group>
            </option_groups>
          </data>
        </question>
      </question_group>
      <question_group select="1">
        <preamble><![CDATA[Assume we have the following co-occurence vectors for the words, "fish", "bird", "ant". 
<br/><br/>
"fish" <br/>
subj-of-A 3 <br/>
mod-of-B 2 <br/>
obj-of-B 4 <br/>
mod-of-C 2 <br/>
<br/>
"bird" <br/>
subj-of-A 3 <br/>
subj-of-D 1 <br/>
mod-of-C 4 <br/>
<br/>
"ant" <br/>
subj-of-A 5 <br/>
mod-of-C 2 <br/>
subj-of-D 1 <br/>
obj-of-B 1 <br/>
<br/>
The numbers above represent the count for the context relation to the left.]]></preamble>
        <question id="cc9bf9ee1a8c3b69b251894aee8935a7" type="GS_Short_Answer_Question_Simple">
          <metadata>
            <parameters>
              <rescale_score>1</rescale_score>
              <type>numeric</type>
            </parameters>
          </metadata>
          <data>
            <text><![CDATA[Assuming that counts not listed are 0, calculate the cosine similarity (using counts, not PMI) for "fish" and "bird". Round your answer to two decimal places (e.g. 0.35, 0.60, 1.43).]]></text>
            <explanation><![CDATA[As an example, consider "fish" and "bird". We first calculate the lengths of these variables. The length of fish is simply $$\sqrt{3^2 + 2^2 + 4^2 + 2^2} = \sqrt{33}$$ and the length of bird is $$\sqrt{3^2 + 4^2 + 1^2} = \sqrt{26}$$. We now compute the dot product of the fish and bird vectors. We see that they share "subj-of-A" and "mod-of-C", which means the counts for those elements are multiplied together. All those counts contribute nothing to the dot product. Thus we have that the dot product is $$3 \times 3 + 2 \times 4 = 17$$. This gives a cosine similarity of $$\frac{17}{\sqrt{26}\sqrt{33}} \approx 0.5804$$]]></explanation>
            <option_groups randomize="true">
              <option_group select="all">
                <option id="bf76e5505f89b11f232ae64e0138e9eb" selected_score="1" unselected_score="0">
                  <text><![CDATA[[0.58,0.59]]]></text>
                  <explanation><![CDATA[]]></explanation>
                </option>
                <option id="b50ae9072592d17bb22963f155a99326" selected_score="0" unselected_score="0">
                  <text><![CDATA[[-99999999,0.57999999]]]></text>
                  <explanation><![CDATA[Remember that in order to take the cross product of two co-occurence vectors, we must align them so that the counts are of the same context.]]></explanation>
                </option>
                <option id="d128719b817fa5cb5d180f2f1e432a87" selected_score="0" unselected_score="0">
                  <text><![CDATA[[0.590000001,999999]]]></text>
                  <explanation><![CDATA[Remember that in order to take the cross product of two co-occurence vectors, we must align them so that the counts are of the same context.]]></explanation>
                </option>
              </option_group>
            </option_groups>
          </data>
        </question>
        <question id="4962db262dcba2a06ca4a7a70029abb6" type="GS_Short_Answer_Question_Simple">
          <metadata>
            <parameters>
              <rescale_score>1</rescale_score>
              <type>numeric</type>
            </parameters>
          </metadata>
          <data>
            <text><![CDATA[Assuming that counts not listed are 0, calculate the cosine similarity (using counts, not PMI) for "fish" and "ant". Round your answer to two decimal places (e.g. 0.35, 0.60, 1.43).]]></text>
            <explanation><![CDATA[Question explanation]]></explanation>
            <option_groups randomize="true">
              <option_group select="all">
                <option id="fce5eed4aa0d27e651f5b04fa4945a51" selected_score="1" unselected_score="0">
                  <text><![CDATA[[0.71,0.72]]]></text>
                  <explanation><![CDATA[]]></explanation>
                </option>
                <option id="6a147fa93d1d5fae0124cc6b0c26b960" selected_score="0" unselected_score="0">
                  <text><![CDATA[[-999999,0.709999]]]></text>
                  <explanation><![CDATA[Remember that in order to take the cross product of two co-occurence vectors, we must align them so that the counts are of the same context.]]></explanation>
                </option>
                <option id="8f9087de1e8f1e457fa1d23858db3d07" selected_score="0" unselected_score="0">
                  <text><![CDATA[[0.720000001,9999999]]]></text>
                  <explanation><![CDATA[Remember that in order to take the cross product of two co-occurence vectors, we must align them so that the counts are of the same context.]]></explanation>
                </option>
              </option_group>
            </option_groups>
          </data>
        </question>
        <question id="fe973ed94739e0854decf4ce1144fba9" type="GS_Short_Answer_Question_Simple">
          <metadata>
            <parameters>
              <rescale_score>1</rescale_score>
              <type>numeric</type>
            </parameters>
          </metadata>
          <data>
            <text><![CDATA[Assuming that counts not listed are 0, calculate the cosine similarity (using counts, not PMI) for "bird" and "ant". Round your answer to two decimal places (e.g. 0.35, 0.60, 1.43).]]></text>
            <explanation><![CDATA[Question explanation]]></explanation>
            <option_groups randomize="true">
              <option_group select="all">
                <option id="9ed22127d7fe44da69039e87ba180dca" selected_score="1" unselected_score="0">
                  <text><![CDATA[[0.84,0.85]]]></text>
                  <explanation><![CDATA[]]></explanation>
                </option>
                <option id="99de008a0f9b4bb24aadcd8ecd14ba3d" selected_score="0" unselected_score="0">
                  <text><![CDATA[[-99999999,0.839999]]]></text>
                  <explanation><![CDATA[Remember that in order to take the cross product of two co-occurence vectors, we must align them so that the counts are of the same context.]]></explanation>
                </option>
                <option id="119a65c79e4a7bd02e654fb5a6c7e7cd" selected_score="0" unselected_score="0">
                  <text><![CDATA[[0.85000001,999999]]]></text>
                  <explanation><![CDATA[Remember that in order to take the cross product of two co-occurence vectors, we must align them so that the counts are of the same context.]]></explanation>
                </option>
              </option_group>
            </option_groups>
          </data>
        </question>
      </question_group>
      <question_group select="1">
        <preamble><![CDATA[Consider the following queries and the results that follow: <br/>
<br/>
What is the capital of California? <br/>
<br/>
1. New York City <br/>
2. Alabama <br/>
3. Sacramento* <br/>
4. Stanford <br/>
<br/>
What is the capital of Georgia? <br/>
<br/>
1. Altanta* <br/>
2. Wyoming <br/>
3. Chicago <br/>
4. Washington DC <br/>
5. China <br/>
6. Steve Jobs <br/>
<br/>
What is the capital of Texas? <br/>
<br/>
1. Denver <br/>
2. Obama <br/>
3. New York City <br/>
<br/>
What is the capital of Massachusetts? <br/>
<br/>
1. Bush <br/>
2. Japan <br/>
3. Massachusetts City <br/>
4. Boston* <br/>
<br/>
What is the capital of Maryland? <br/>
<br/>
1. Facebook <br/>
2. Africa <br/>
3. Los Angeles <br/>
4. Annapolis* <br/>
5. England <br/>
<br/>
What is the capital of Nevada? <br/>
<br/>
1. Flag <br/>
2. Baton Rouge <br/>
3. Montana <br/>
4. Disney World <br/>
5. New Zealand <br/>]]></preamble>
        <question id="98329cc9be22e1c923ac0542e6628a6b" type="GS_Short_Answer_Question_Simple">
          <metadata>
            <parameters>
              <rescale_score>1</rescale_score>
              <type>numeric</type>
            </parameters>
          </metadata>
          <data>
            <text><![CDATA[Note that answers which are followed by an asterisk are the correct answers to the query. What is the mean reciprocal rank for the set of queries over the capital of the following set of states:
<br/><br/>
California, Georgia, Texas, Massachusetts
<br/><br/>
Round your answer to two decimal places (e.g. 0.35, 0.60, 1.43).]]></text>
            <explanation><![CDATA[As an example, consider the query set for California, Georgia, Texas, and Massachusetts. In these queries, the correct answer appeared in position 3, 1, never, and 4, respectively. Taking the reciprocals of these values yields 1/3, 1, 0, and 1/4, where a list that does not contain the correct result receives a reciprocal rank of 0. Averaging the reciprocals by taking the sum and dividing by 4 gives 19/48 $$\approx$$ 0.396]]></explanation>
            <option_groups randomize="true">
              <option_group select="all">
                <option id="6c88cad281d32ebfda87e66ff8a72273" selected_score="1" unselected_score="0">
                  <text><![CDATA[[0.39,0.40]]]></text>
                  <explanation><![CDATA[]]></explanation>
                </option>
                <option id="a36f6b211de5287c3a80e4970196b202" selected_score="0" unselected_score="0">
                  <text><![CDATA[[-9999999,0.389999999]]]></text>
                  <explanation><![CDATA[Remember that lists which don't contain the correct answer have a reciprocal rank of 0.]]></explanation>
                </option>
                <option id="9a635b2ff45f91cdfaa25f2701dc0d90" selected_score="0" unselected_score="0">
                  <text><![CDATA[[0.40000001,99999999]]]></text>
                  <explanation><![CDATA[Remember that lists which don't contain the correct answer have a reciprocal rank of 0.]]></explanation>
                </option>
              </option_group>
            </option_groups>
          </data>
        </question>
        <question id="e6a3933ccad69a1a2a11380f3dcfeffd" type="GS_Short_Answer_Question_Simple">
          <metadata>
            <parameters>
              <rescale_score>1</rescale_score>
              <type>numeric</type>
            </parameters>
          </metadata>
          <data>
            <text><![CDATA[Note that answers which are followed by an asterisk are the correct answers to the query. What is the mean reciprocal rank for the set of queries over the capital of the following set of states:
<br/><br/>
California, Texas, Maryland, Nevada
<br/><br/>
Round your answer to two decimal places (e.g. 0.35, 0.60, 1.43).]]></text>
            <explanation><![CDATA[As an example, consider the query set for California, Georgia, Texas, and Massachusetts. In these queries, the correct answer appeared in position 3, 1, never, and 4, respectively. Taking the reciprocals of these values yields 1/3, 1, 0, and 1/4, where a list that does not contain the correct result receives a reciprocal rank of 0. Averaging the reciprocals by taking the sum and dividing by 4 gives 19/48 $$\approx$$ 0.396]]></explanation>
            <option_groups randomize="true">
              <option_group select="all">
                <option id="5ed0f1c78b4b38556b33a2ca0380ccc8" selected_score="1" unselected_score="0">
                  <text><![CDATA[[0.14,0.15]]]></text>
                  <explanation><![CDATA[]]></explanation>
                </option>
                <option id="e59893b9fbac41608d0de0a844b47064" selected_score="0" unselected_score="0">
                  <text><![CDATA[[-99999999,0.139999999]]]></text>
                  <explanation><![CDATA[Remember that lists which don't contain the correct answer have a reciprocal rank of 0.]]></explanation>
                </option>
                <option id="b0baf098238ecf1a2c5fa16e3d9624e9" selected_score="0" unselected_score="0">
                  <text><![CDATA[[0.15000001,99999999]]]></text>
                  <explanation><![CDATA[Remember that lists which don't contain the correct answer have a reciprocal rank of 0.]]></explanation>
                </option>
              </option_group>
            </option_groups>
          </data>
        </question>
        <question id="61f66a271be937a449a47d83497e5f95" type="GS_Short_Answer_Question_Simple">
          <metadata>
            <parameters>
              <rescale_score>1</rescale_score>
              <type>numeric</type>
            </parameters>
          </metadata>
          <data>
            <text><![CDATA[Note that answers which are followed by an asterisk are the correct answers to the query. What is the mean reciprocal rank for the set of queries over the capital of the following set of states:
<br/><br/>
Texas, Massachusetts, Maryland, Nevada
<br/><br/>
Round your answer to two decimal places (e.g. 0.35, 0.60, 1.43).]]></text>
            <explanation><![CDATA[As an example, consider the query set for California, Georgia, Texas, and Massachusetts. In these queries, the correct answer appeared in position 3, 1, never, and 4, respectively. Taking the reciprocals of these values yields 1/3, 1, 0, and 1/4, where a list that does not contain the correct result receives a reciprocal rank of 0. Averaging the reciprocals by taking the sum and dividing by 4 gives 19/48 $$\approx$$ 0.396]]></explanation>
            <option_groups randomize="true">
              <option_group select="all">
                <option id="df0f040fa5393277f3c2e97c875515c3" selected_score="1" unselected_score="0">
                  <text><![CDATA[[0.12,0.13]]]></text>
                  <explanation><![CDATA[]]></explanation>
                </option>
                <option id="5dbe119e24b939d82e94d5877790a754" selected_score="0" unselected_score="0">
                  <text><![CDATA[[-9999999,0.119999999]]]></text>
                  <explanation><![CDATA[Remember that lists which don't contain the correct answer have a reciprocal rank of 0.]]></explanation>
                </option>
                <option id="5a78d3c8e5d3d7663cd81a0de9c4a145" selected_score="0" unselected_score="0">
                  <text><![CDATA[[0.1300001,9999999]]]></text>
                  <explanation><![CDATA[Remember that lists which don't contain the correct answer have a reciprocal rank of 0.]]></explanation>
                </option>
              </option_group>
            </option_groups>
          </data>
        </question>
        <question id="bcebfb2eddd824a8fb81c43976773b0b" type="GS_Short_Answer_Question_Simple">
          <metadata>
            <parameters>
              <rescale_score>1</rescale_score>
              <type>numeric</type>
            </parameters>
          </metadata>
          <data>
            <text><![CDATA[Note that answers which are followed by an asterisk are the correct answers to the query. What is the mean reciprocal rank for the set of queries over the capital of the following set of states:
<br/><br/>
Georgia, Texas, Massachusetts, Nevada
<br/><br/>
Round your answer to two decimal places (e.g. 0.35, 0.60, 1.43).]]></text>
            <explanation><![CDATA[As an example, consider the query set for California, Georgia, Texas, and Massachusetts. In these queries, the correct answer appeared in position 3, 1, never, and 4, respectively. Taking the reciprocals of these values yields 1/3, 1, 0, and 1/4, where a list that does not contain the correct result receives a reciprocal rank of 0. Averaging the reciprocals by taking the sum and dividing by 4 gives 19/48 $$\approx$$ 0.396]]></explanation>
            <option_groups randomize="true">
              <option_group select="all">
                <option id="2a8b9d3b4b84b138c78d4dfe7b3bc913" selected_score="1" unselected_score="0">
                  <text><![CDATA[[0.31,0.32]]]></text>
                  <explanation><![CDATA[]]></explanation>
                </option>
                <option id="3d1441155cc5d5ec174d629660a08a1a" selected_score="0" unselected_score="0">
                  <text><![CDATA[[-9999999,0.30999999]]]></text>
                  <explanation><![CDATA[Remember that lists which don't contain the correct answer have a reciprocal rank of 0.]]></explanation>
                </option>
                <option id="9badd7d79c10fb0f926eb540bb95aca5" selected_score="0" unselected_score="0">
                  <text><![CDATA[[0.3200001,999999]]]></text>
                  <explanation><![CDATA[Remember that lists which don't contain the correct answer have a reciprocal rank of 0.]]></explanation>
                </option>
              </option_group>
            </option_groups>
          </data>
        </question>
        <question id="b100f2bdb98ed1ae76b13cf6fe237473" type="GS_Short_Answer_Question_Simple">
          <metadata>
            <parameters>
              <rescale_score>1</rescale_score>
              <type>numeric</type>
            </parameters>
          </metadata>
          <data>
            <text><![CDATA[Note that answers which are followed by an asterisk are the correct answers to the query. What is the mean reciprocal rank for the set of queries over the capital of the following set of states:
<br/><br/>
California, Georgia, Massachusetts, Maryland
<br/><br/>
Round your answer to two decimal places (e.g. 0.35, 0.60, 1.43).]]></text>
            <explanation><![CDATA[As an example, consider the query set for California, Georgia, Texas, and Massachusetts. In these queries, the correct answer appeared in position 3, 1, never, and 4, respectively. Taking the reciprocals of these values yields 1/3, 1, 0, and 1/4, where a list that does not contain the correct result receives a reciprocal rank of 0. Averaging the reciprocals by taking the sum and dividing by 4 gives 19/48 $$\approx$$ 0.396]]></explanation>
            <option_groups randomize="true">
              <option_group select="all">
                <option id="107066d49fe23d7635a69ccf333ced04" selected_score="1" unselected_score="0">
                  <text><![CDATA[[0.45,0.46]]]></text>
                  <explanation><![CDATA[]]></explanation>
                </option>
                <option id="2554e38f9e59ad93e7eae5ec50f2218d" selected_score="0" unselected_score="0">
                  <text><![CDATA[[-9999999,0.44999999]]]></text>
                  <explanation><![CDATA[Remember that lists which don't contain the correct answer have a reciprocal rank of 0.]]></explanation>
                </option>
                <option id="abb0db6900629b0ee57989898b8330d9" selected_score="0" unselected_score="0">
                  <text><![CDATA[[0.46000001,999999]]]></text>
                  <explanation><![CDATA[Remember that lists which don't contain the correct answer have a reciprocal rank of 0.]]></explanation>
                </option>
              </option_group>
            </option_groups>
          </data>
        </question>
      </question_group>
    </question_groups>
  </data>
</quiz>

