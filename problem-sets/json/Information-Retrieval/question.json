{"metadata":{"title":"Information Retrieval","open_time":"2012-02-07 2201","soft_close_time":"2012-05-15 2359","hard_close_time":"2012-05-22 2359","duration":"0","retry_delay":"10","maximum_submissions":"5","modified_time":"1336933132604","parameters":{"show_explanations":{"question":"after_hard_close_time","option":"before_soft_close_time","score":"before_soft_close_time"}},"maximum_score":"4"},"preamble":{},"data":{"question_groups":{"question_group":[{"@attributes":{"select":"1"},"preamble":{},"question":[{"@attributes":{"id":"564d6a72003c63a41e737f32436e23c5","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"Given the two documents:\n<br \/><br \/>\n<ul>\n<li><strong><em>Sam is Sam and is a ham.<\/em><\/strong><\/li>\n<li><strong><em>Sam likes me, ham and Sam!<\/em><\/strong><\/li>\n<\/ul>\nWhat is the Jaccard similarity between them (ignoring punctuation)?","explanation":"The Jaccard coefficient between two documents is given by $$\\frac{|D_1 \\cap D_1 | }{ | D_1 \\cup D_2 |}$$, where $$D_1$$ is the set of words occurring in document $$1$$ and $$D_2$$ is the set of words occurring in document $$2$$ - i.e. it is the number of distinct word types occurring in both documents divided by the number of distinct word types occurring in either of the documents.","option_groups":{"@attributes":{"randomize":"true"},"option_group":{"@attributes":{"select":"all"},"option":[{"@attributes":{"id":"10101648be75a9f48fe98a38bbdda33a","selected_score":"1","unselected_score":"0"},"text":"$$\\frac{3}{7}$$","explanation":"Correct. Only <strong><em>Sam<\/em><\/strong>, <strong><em>and<\/em><\/strong>, and <strong><em>ham<\/em><\/strong> occur in both documents, and there are $$7$$ distinct word types, so we get the Jaccard coefficient is $$3 \/ 7$$."},{"@attributes":{"id":"b5993476062b48009072b30cfcaec501","selected_score":"0","unselected_score":"0"},"text":"$$\\frac{3}{13}$$","explanation":"You may have thought that the denominator of the Jaccard coefficient is the total number of words in the two documents ($$13$$). However, it is actually the total number of <em>distinct<\/em> word types in the two sentences together ($$7$$)."},{"@attributes":{"id":"90b6955fbd7309a9ab1530114e4d5569","selected_score":"0","unselected_score":"0"},"text":"$$\\frac{4}{13}$$","explanation":"You may have thought the numerator is the number of total word tokens that are shared between the two documents ($$4$$) and the denominator is the total number of word tokens in the documents together ($$13$$). However, the numerator is actually the number of distinct word types shared by both documents ($$3$$) and the denominator is the total number of distinct word types in either document ($$7$$)."},{"@attributes":{"id":"e05f54d3010e2c3d81a5350bd5ca387b","selected_score":"0","unselected_score":"0"},"text":"$$\\frac{4}{7}$$","explanation":"You may have thought to include <strong><em>Sam<\/em><\/strong> twice in the numerator - however, it should only be included once because with the Jaccard coefficient we care only about whether a word occurs in a document, not how many times."}]}}}},{"@attributes":{"id":"0f95aeade29bfda895da95b1fcd63299","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"Given the two documents:\n<br \/><br \/>\n<ul>\n<li><strong><em>To be or not to be.<\/em><\/strong><\/li>\n<li><strong><em>To think and therefore to be.<\/em><\/strong><\/li>\n<\/ul>\nWhat is the Jaccard similarity between them (ignoring punctuation)?","explanation":"The Jaccard coefficient between two documents is given by $$\\frac{|D_1 \\cap D_1 | }{ | D_1 \\cup D_2 |}$$, where $$D_1$$ is the set of words occurring in document $$1$$ and $$D_2$$ is the set of words occurring in document $$2$$ - i.e. it is the number of distinct word types occurring in both documents divided by the number of distinct word types occurring in either of the documents.","option_groups":{"@attributes":{"randomize":"true"},"option_group":{"@attributes":{"select":"all"},"option":[{"@attributes":{"id":"a30819fb60d1c2ab1bf92c37bed9caa9","selected_score":"0","unselected_score":"0"},"text":"$$\\frac{1}{6}$$","explanation":"You may have thought that the denominator of the Jaccard coefficient is the total number of words in the two documents ($$12$$). However, it is actually the total number of <em>distinct<\/em> word types in the two sentences together ($$7$$)."},{"@attributes":{"id":"34919b170984cc2d6346c7c8625966da","selected_score":"0","unselected_score":"0"},"text":"$$\\frac{1}{4}$$","explanation":"You may have thought that the denominator is the total number of words in the two documents ($$12$$), but it is actually the total number of <em>distinct<\/em> word tokens in the documents ($$7$$). You may have also thought that the numerator is the number of one-to-one matches of words in one document to words in the other document ($$3$$). However, it is actually the number of distinct word types that are shared between the documents ($$2$$)."},{"@attributes":{"id":"8db582e5867f602eb697f169ce5c95a7","selected_score":"1","unselected_score":"0"},"text":"$$\\frac{2}{7}$$","explanation":"Correct. Only <strong><em>to<\/em><\/strong> and <strong><em>be<\/em><\/strong> occur in both documents, and there are $$7$$ distinct word types, so we get the Jaccard coefficient is $$2 \/ 7$$."},{"@attributes":{"id":"fa36b397f90a149a780a280ad146392b","selected_score":"0","unselected_score":"0"},"text":"$$\\frac{7}{12}$$","explanation":"You may have thought the numerator is the number of total word tokens that are shared between the two documents ($$7$$) and the denominator is the total number of word types in the documents together ($$12$$). However, the numerator is actually the number of distinct word types shared by both documents ($$2$$) and the denominator is the total number of distinct word types in either document ($$7$$)."}]}}}},{"@attributes":{"id":"d9b12e0ff3e973ed01fe2b9f2c5c2785","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"Given the two documents:\n<br \/><br \/>\n<ul>\n<li><strong><em>We all live in that yellow submarine.<\/em><\/strong><\/li>\n<li><strong><em>The yellow mustard in that submarine sandwich was not yellow!<\/em><\/strong><\/li>\n<\/ul>\nWhat is the Jaccard similarity between them (ignoring punctuation)?","explanation":"The Jaccard coefficient between two documents is given by $$\\frac{|D_1 \\cap D_1 | }{ | D_1 \\cup D_2 |}$$, where $$D_1$$ is the set of words occurring in document $$1$$ and $$D_2$$ is the set of words occurring in document $$2$$ - i.e. it is the number of distinct word types occurring in both documents divided by the number of distinct word types occurring in either of the documents.","option_groups":{"@attributes":{"randomize":"true"},"option_group":{"@attributes":{"select":"all"},"option":[{"@attributes":{"id":"38979ca494ee7fd1af23b6c4b548306f","selected_score":"0","unselected_score":"0"},"text":"$$\\frac{4}{17}$$","explanation":"The denominator should be the total number of <em>distinct word types<\/em> that occur in the two documents together, not the total number of words that occur in them."},{"@attributes":{"id":"123b146362011a7e1586a5238b75da0c","selected_score":"0","unselected_score":"0"},"text":"$$\\frac{9}{17}$$","explanation":"You probably thought that the numerator is the number of words that occur in both documents ($$9$$) and the denominator is the number of total words in the two documents combined ($$17$$). However, the numerator is actually the total number of distinct word types that are shared by the two documents ($$4$$) and the denominator is the total number of distinct word types in either of the documents ($$12$$)."},{"@attributes":{"id":"23d6eb24fe633a04392be50926ed9083","selected_score":"1","unselected_score":"0"},"text":"$$\\frac{1}{3}$$","explanation":"Correct. Exactly $$4$$ distinct words (<strong><em>in<\/em><\/strong>, <strong><em>that<\/em><\/strong>, <strong><em>yellow<\/em><\/strong>, and <strong><em>submarine<\/em><\/strong>) occur in both documents, and there are $$12$$ distinct word types, so we get the Jaccard coefficient is $$4 \/ 12 = 1 \/ 3$$."},{"@attributes":{"id":"2088a9e2a68c652925d3a9075bd582ca","selected_score":"0","unselected_score":"0"},"text":"$$\\frac{8}{17}$$","explanation":"You may have thought that the denominator is the total number of words in the two documents ($$17$$), but it is actually the total number of <em>distinct<\/em> word types in the documents ($$17$$). You may have also thought that the numerator is the number of words in a document that match one-to-one to a word in the other document ($$8$$). However, it is actually the number of distinct word types that are shared between the documents ($$4$$)."}]}}}}]},{"@attributes":{"select":"1"},"preamble":{},"question":[{"@attributes":{"id":"546ddef8f0ce62caf20111141b7547b8","type":"GS_Short_Answer_Question_Simple"},"metadata":{"parameters":{"rescale_score":"1","type":"numeric"}},"data":{"text":"In a set of $$806,791$$ documents, we get the following data on a few terms and a few documents:\n<br \/><br \/>\n<table>\n<tr><th>term<\/th><th>document frequency<\/th><th>Doc 1<\/th><th>Doc 2<\/th><th>Doc 3<\/th><\/tr>\n<tr><td>car<\/td><td>$$18,165$$<\/td><td>$$27$$<\/td><td>$$4$$<\/td><td>$$24$$<\/td><\/tr>\n<tr><td>auto<\/td><td>$$6723$$<\/td><td>$$3$$<\/td><td>$$33$$<\/td><td>$$0$$<\/td><\/tr>\n<tr><td>insurance<\/td><td>$$19,241$$<\/td><td>$$0$$<\/td><td>$$39$$<\/td><td>$$29$$<\/td><\/tr>\n<tr><td>best<\/td><td>$$25,235$$<\/td><td>$$14$$<\/td><td>$$0$$<\/td><td>$$17$$<\/td><\/tr>\n<\/table>\n<br \/>\nWhat is the tf-idf value for the term <strong><em>insurance<\/em><\/strong> in Document 2?\n<br \/><br \/>\n(Please answer to $$3$$ decimal places - e.g. $$5.18254 \\rightarrow 5.183$$ or $$1.128333 \\rightarrow 1.128$$).\n<br \/>\nNote: Be sure to use $$\\log_{10}$$ (log base 10) in your calculations.","explanation":"TF-IDF for a term $$t$$ in a document $$d$$ is given by\n<br \/>\n$$w_{t, d} = (1 + \\log_{10} \\textrm{tf}_{t, d} ) \\times \\log_{10} ( N \/ \\textrm{df}_t )$$","option_groups":{"@attributes":{"randomize":"true"},"option_group":{"@attributes":{"select":"all"},"option":{"@attributes":{"id":"d70b6a22c464cab25e531fa28e1a6fe2","selected_score":"1","unselected_score":"0"},"text":"[4.201,4.207]","explanation":"Correct. The TF-IDF is given by\n<br \/>\n$$(1 + \\log_{10} 39 ) \\times \\log_{10} ( 806,791\/19,241 )$$\n<br \/>\n$$\\approx 2.591 \\times 1.623$$"}}}}},{"@attributes":{"id":"3e689a8fdf7e25c882ed07261fc0d6db","type":"GS_Short_Answer_Question_Simple"},"metadata":{"parameters":{"rescale_score":"1","type":"numeric"}},"data":{"text":"In a set of $$806,791$$ documents, we get the following data on a few terms and a few documents:\n<br \/><br \/>\n<table>\n<tr><th>term<\/th><th>document frequency<\/th><th>Doc 1<\/th><th>Doc 2<\/th><th>Doc 3<\/th><\/tr>\n<tr><td>car<\/td><td>$$18,165$$<\/td><td>$$27$$<\/td><td>$$4$$<\/td><td>$$24$$<\/td><\/tr>\n<tr><td>auto<\/td><td>$$6723$$<\/td><td>$$3$$<\/td><td>$$33$$<\/td><td>$$0$$<\/td><\/tr>\n<tr><td>insurance<\/td><td>$$19,241$$<\/td><td>$$0$$<\/td><td>$$39$$<\/td><td>$$29$$<\/td><\/tr>\n<tr><td>best<\/td><td>$$25,235$$<\/td><td>$$14$$<\/td><td>$$0$$<\/td><td>$$17$$<\/td><\/tr>\n<\/table>\n<br \/>\nWhat is the tf-idf value for the term <strong><em>car<\/em><\/strong> in Document 1?\n<br \/><br \/>\n(Please answer to $$3$$ decimal places - e.g. $$5.18254 \\rightarrow 5.183$$ or $$1.128333 \\rightarrow 1.128$$).\n<br \/>\nNote: Be sure to use $$\\log_{10}$$ (log base 10) in your calculations.","explanation":"TF-IDF for a term $$t$$ in a document $$d$$ is given by\n<br \/>\n$$w_{t, d} = (1 + \\log_{10} \\textrm{tf}_{t, d} ) \\times \\log_{10} ( N \/ \\textrm{df}_t )$$","option_groups":{"@attributes":{"randomize":"true"},"option_group":{"@attributes":{"select":"all"},"option":{"@attributes":{"id":"19c90051081169f2c9cd6466af39fead","selected_score":"1","unselected_score":"0"},"text":"[4.003,4.009]","explanation":"Correct. The TF-IDF is given by\n<br \/>\n$$(1 + \\log_{10} 27 ) \\times \\log_{10} ( 806,791\/18,165 )$$\n<br \/>\n$$\\approx 2.431 \\times 1.648$$"}}}}},{"@attributes":{"id":"e36d3d71d2e3a563b0a39fe045ed6d6d","type":"GS_Short_Answer_Question_Simple"},"metadata":{"parameters":{"rescale_score":"1","type":"numeric"}},"data":{"text":"In a set of $$806,791$$ documents, we get the following data on a few terms and a few documents:\n<br \/><br \/>\n<table>\n<tr><th>term<\/th><th>document frequency<\/th><th>Doc 1<\/th><th>Doc 2<\/th><th>Doc 3<\/th><\/tr>\n<tr><td>car<\/td><td>$$18,165$$<\/td><td>$$27$$<\/td><td>$$4$$<\/td><td>$$24$$<\/td><\/tr>\n<tr><td>auto<\/td><td>$$6723$$<\/td><td>$$3$$<\/td><td>$$33$$<\/td><td>$$0$$<\/td><\/tr>\n<tr><td>insurance<\/td><td>$$19,241$$<\/td><td>$$0$$<\/td><td>$$39$$<\/td><td>$$29$$<\/td><\/tr>\n<tr><td>best<\/td><td>$$25,235$$<\/td><td>$$14$$<\/td><td>$$0$$<\/td><td>$$17$$<\/td><\/tr>\n<\/table>\n<br \/>\nWhat is the tf-idf value for the term <strong><em>best<\/em><\/strong> in Document 3?\n<br \/><br \/>\n(Please answer to $$3$$ decimal places - e.g. $$5.18254 \\rightarrow 5.183$$ or $$1.128333 \\rightarrow 1.128$$).\n<br \/>\nNote: Be sure to use $$\\log_{10}$$ (log base 10) in your calculations.","explanation":"TF-IDF for a term $$t$$ in a document $$d$$ is given by\n<br \/>\n$$w_{t, d} = (1 + \\log_{10} \\textrm{tf}_{t, d} ) \\times \\log_{10} ( N \/ \\textrm{df}_t )$$","option_groups":{"@attributes":{"randomize":"true"},"option_group":{"@attributes":{"select":"all"},"option":{"@attributes":{"id":"e03531120487e4a96114820631771450","selected_score":"1","unselected_score":"0"},"text":"[3.353,3.359]","explanation":"Correct. The TF-IDF is given by\n<br \/>\n$$(1 + \\log_{10} 17 ) \\times \\log_{10} ( 806,791\/25,235 )$$\n<br \/>\n$$\\approx 2.230 \\times 1.505$$"}}}}}]},{"@attributes":{"select":"1"},"preamble":{},"question":[{"@attributes":{"id":"ded4139672e43df2c752faa47864876a","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"Given the following term frequencies (counts) for a few words in a collection of $$4$$ documents,\n<br \/><br \/>\n<table>\n<tr><th>term<\/th><th>Dawn<\/th><th>Beatrice<\/th><th>She<\/th><th>Regeneration<\/th><\/tr>\n<tr><td>happiness<\/td><td>37<\/td><td>30<\/td><td>0<\/td><td>3<\/td><\/tr>\n<tr><td>surprise<\/td><td>40<\/td><td>10<\/td><td>6<\/td><td>0<\/td><\/tr>\n<tr><td>family<\/td><td>31<\/td><td>0<\/td><td>12<\/td><td>17<\/td><\/tr>\n<tr><td>adventure<\/td><td>0<\/td><td>5<\/td><td>13<\/td><td>0<\/td><\/tr>\n<\/table>\nWhat is the cosine similarity between <em>Dawn<\/em> and <em>Beatrice<\/em>? Use tf-idf weighting and assume that these are the only documents and words in the collection.","explanation":{},"option_groups":{"@attributes":{"randomize":"true"},"option_group":{"@attributes":{"select":"all"},"option":[{"@attributes":{"id":"70efc7e3b1354759c7bc42d815ef14e9","selected_score":"0","unselected_score":"0"},"text":"$$0.78$$","explanation":"You may have made the mistake of thinking the idf term is $$\\log_{10} (\\textrm{df}_t)$$. Remember, it is the <em>inverse<\/em> document frequency, and is given by $$\\log_{10} (N \/ \\textrm{df}_t)$$, where $$N$$ is the number of documents (here $$4$$)."},{"@attributes":{"id":"d20ca9e2920c2538cff020b90ba9a9d0","selected_score":"0","unselected_score":"0"},"text":"$$0.72$$","explanation":"Don't forget the idf term! You may have forgotten to multiply by $$\\log_{10} (N \/ \\textrm{df}_t)$$ (where $$N$$ here is $$4$$)."},{"@attributes":{"id":"0ac06d6927f292abe6388a2f0285b3a1","selected_score":"0","unselected_score":"0"},"text":"$$0.59$$","explanation":"Don't forget that you must add $$1$$ to the tf term in TF-IDF - i.e. the term frequency contribution to TF-IDF is $$1 + \\log_{10} \\textrm{tf}_{t, d}$$."},{"@attributes":{"id":"e14883cb8cb4d7837ec67b868ce3e921","selected_score":"1","unselected_score":"0"},"text":"$$0.50$$","explanation":"Correct!"}]}}}},{"@attributes":{"id":"5cf458545ad54a337265386ad3158bc5","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"Given the following term frequencies (counts) for a few words in a collection of $$4$$ documents,\n<br \/><br \/>\n<table>\n<tr><th>term<\/th><th>Dawn<\/th><th>Beatrice<\/th><th>She<\/th><th>Regeneration<\/th><\/tr>\n<tr><td>happiness<\/td><td>37<\/td><td>30<\/td><td>0<\/td><td>3<\/td><\/tr>\n<tr><td>surprise<\/td><td>40<\/td><td>10<\/td><td>6<\/td><td>0<\/td><\/tr>\n<tr><td>family<\/td><td>31<\/td><td>0<\/td><td>12<\/td><td>17<\/td><\/tr>\n<tr><td>adventure<\/td><td>0<\/td><td>5<\/td><td>13<\/td><td>0<\/td><\/tr>\n<\/table>\nWhat is the cosine similarity between <em>Beatrice<\/em> and <em>She<\/em>? Use tf-idf weighting and assume that these are the only documents and words in the collection.","explanation":{},"option_groups":{"@attributes":{"randomize":"true"},"option_group":{"@attributes":{"select":"all"},"option":[{"@attributes":{"id":"6290d9e3e0aa3cacc0e65027fc3ef114","selected_score":"0","unselected_score":"0"},"text":"$$0.72$$","explanation":"Don't forget that you must add $$1$$ to the tf term in TF-IDF - i.e. the term frequency contribution to TF-IDF is $$1 + \\log_{10} \\textrm{tf}_{t, d}$$."},{"@attributes":{"id":"2395e2ab9a63a162063a22ff13abeb18","selected_score":"1","unselected_score":"0"},"text":"$$0.81$$","explanation":"Correct!"},{"@attributes":{"id":"cb484de512d12c28ec7defb405f282c7","selected_score":"0","unselected_score":"0"},"text":"$$0.49$$","explanation":"You may have made the mistake of thinking the idf term is $$\\log_{10} (\\textrm{df}_t)$$. Remember, it is the <em>inverse<\/em> document frequency, and is given by $$\\log_{10} (N \/ \\textrm{df}_t)$$, where $$N$$ is the number of documents (here $$4$$)."},{"@attributes":{"id":"cbe5a20e67416c6875c5f235d2f545d5","selected_score":"0","unselected_score":"0"},"text":"$$0.57$$","explanation":"Don't forget the idf term! You may have forgotten to multiply by $$\\log_{10} (N \/ \\textrm{df}_t)$$ (where $$N$$ here is $$4$$)."}]}}}},{"@attributes":{"id":"ffd9853444dd50059b6d3d7240d33057","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"Given the following term frequencies (counts) for a few words in a collection of $$4$$ documents,\n<br \/><br \/>\n<table>\n<tr><th>term<\/th><th>Dawn<\/th><th>Beatrice<\/th><th>She<\/th><th>Regeneration<\/th><\/tr>\n<tr><td>happiness<\/td><td>37<\/td><td>30<\/td><td>0<\/td><td>3<\/td><\/tr>\n<tr><td>surprise<\/td><td>40<\/td><td>10<\/td><td>6<\/td><td>0<\/td><\/tr>\n<tr><td>family<\/td><td>31<\/td><td>0<\/td><td>12<\/td><td>17<\/td><\/tr>\n<tr><td>adventure<\/td><td>0<\/td><td>5<\/td><td>13<\/td><td>0<\/td><\/tr>\n<\/table>\nWhat is the cosine similarity between <em>Beatrice<\/em> and <em>Regeneration<\/em>? Use tf-idf weighting and assume that these are the only documents and words in the collection.","explanation":{},"option_groups":{"@attributes":{"randomize":"true"},"option_group":{"@attributes":{"select":"all"},"option":[{"@attributes":{"id":"c53783637ae33289e03520bab2e5db52","selected_score":"0","unselected_score":"0"},"text":"$$0.41$$","explanation":"You may have made the mistake of thinking the idf term is $$\\log_{10} (\\textrm{df}_t)$$. Remember, it is the <em>inverse<\/em> document frequency, and is given by $$\\log_{10} (N \/ \\textrm{df}_t)$$, where $$N$$ is the number of documents (here $$4$$)."},{"@attributes":{"id":"5373ef9d98e82ba253ddd71d7286e1f4","selected_score":"0","unselected_score":"0"},"text":"$$0.38$$","explanation":"Don't forget the idf term! You may have forgotten to multiply by $$\\log_{10} (N \/ \\textrm{df}_t)$$ (where $$N$$ here is $$4$$)."},{"@attributes":{"id":"e87c051a0d3827d89b71a8e1e3d5c611","selected_score":"1","unselected_score":"0"},"text":"$$0.26$$","explanation":"Correct!"},{"@attributes":{"id":"b7c70aa4ba06df997328846087b2c5b6","selected_score":"0","unselected_score":"0"},"text":"$$0.22$$","explanation":"Don't forget that you must add $$1$$ to the tf term in TF-IDF - i.e. the term frequency contribution to TF-IDF is $$1 + \\log_{10} \\textrm{tf}_{t, d}$$."}]}}}},{"@attributes":{"id":"94bf71a362443b61ac08cf35d4c84265","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"Given the following term frequencies (counts) for a few words in a collection of $$4$$ documents,\n<br \/><br \/>\n<table>\n<tr><th>term<\/th><th>Dawn<\/th><th>Beatrice<\/th><th>She<\/th><th>Regeneration<\/th><\/tr>\n<tr><td>happiness<\/td><td>37<\/td><td>30<\/td><td>0<\/td><td>3<\/td><\/tr>\n<tr><td>surprise<\/td><td>40<\/td><td>10<\/td><td>6<\/td><td>0<\/td><\/tr>\n<tr><td>family<\/td><td>31<\/td><td>0<\/td><td>12<\/td><td>17<\/td><\/tr>\n<tr><td>adventure<\/td><td>0<\/td><td>5<\/td><td>13<\/td><td>0<\/td><\/tr>\n<\/table>\nWhat is the cosine similarity between <em>Dawn<\/em> and <em>She<\/em>? Use tf-idf weighting (ltc variation) and assume that these are the only documents and words in the collection.","explanation":{},"option_groups":{"@attributes":{"randomize":"true"},"option_group":{"@attributes":{"select":"all"},"option":[{"@attributes":{"id":"cec394c70f9a2aea67fe4555f76be02e","selected_score":"1","unselected_score":"0"},"text":"$$0.38$$","explanation":"Correct!"},{"@attributes":{"id":"1024669b7faef9b6323956c3db11b4b7","selected_score":"0","unselected_score":"0"},"text":"$$0.35$$","explanation":"Don't forget that you must add $$1$$ to the tf term in TF-IDF - i.e. the term frequency contribution to TF-IDF is $$1 + \\log_{10} \\textrm{tf}_{t, d}$$."},{"@attributes":{"id":"d16a18557c8b853a2383d8038e517394","selected_score":"0","unselected_score":"0"},"text":"$$0.64$$","explanation":"Don't forget the idf term! You may have forgotten to multiply by $$\\log_{10} (N \/ \\textrm{df}_t)$$ (where $$N$$ here is $$4$$)."},{"@attributes":{"id":"893efd38574722800d452b41be1a58e7","selected_score":"0","unselected_score":"0"},"text":"$$0.73$$","explanation":"You may have made the mistake of thinking the idf term is $$\\log_{10} (\\textrm{df}_t)$$. Remember, it is the <em>inverse<\/em> document frequency, and is given by $$\\log_{10} (N \/ \\textrm{df}_t)$$, where $$N$$ is the number of documents (here $$4$$)."}]}}}}]},{"@attributes":{"select":"1"},"preamble":{},"question":[{"@attributes":{"id":"46f82a577d421a7dfb9bb4148f15087a","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"What is the average precision for the following sequence of retrieved documents, where <strong>R<\/strong> denotes a relevant document and <strong>N<\/strong> denotes an irrelevant document?\n<br \/><br \/>\n<strong>R N R R N N N R R N N R<\/strong>","explanation":"Recall that average precision is calculated by scanning through the list of retrieved documents (in the order that they are reported) and computing the precision at every point that we retrieve a relevant document. We then get the Average Precision by averaging over those precisions. Also recall that precision in this context is the number of relevant documents retrieved so far divided by the number of documents retrieved so far.","option_groups":{"@attributes":{"randomize":"true"},"option_group":{"@attributes":{"select":"all"},"option":[{"@attributes":{"id":"7bd914ba2c150d0574aadda06d33eb7b","selected_score":"0","unselected_score":"0"},"text":"$$0.500$$","explanation":"You may have calculated the precision just at the last relevant document retrieved. You have to calculate the precision at every point that you retrieve a relevant document and then take the average of those precisions."},{"@attributes":{"id":"8ae61cb26f95a13733de86af019ef281","selected_score":"1","unselected_score":"0"},"text":"$$0.662$$","explanation":"Correct!"},{"@attributes":{"id":"79df8fc8cdf8e03a40ae450fec2a9165","selected_score":"0","unselected_score":"0"},"text":"$$0.580$$","explanation":"You may have calculated the precision at every point that a document is retrieved. However, you should only calculate the precision at the points when a relevant document is retrieved, and then report the average of those precisions."},{"@attributes":{"id":"dabed3a9d6fb0c3fa909279462064433","selected_score":"0","unselected_score":"0"},"text":"$$0.497$$","explanation":"You may have calculated the precision at every point that an irrelevant document is retrieved and taken the average of those precisions. You are supposed to calculate the precision at every point that a <em>relevant<\/em> document is retrieved and report the mean of those precisions."}]}}}},{"@attributes":{"id":"12d70e4dedcae7107fa5f0d506c9b67d","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"What is the average precision for the following sequence of retrieved documents, where <strong>R<\/strong> denotes a relevant document and <strong>N<\/strong> denotes an irrelevant document?\n<br \/><br \/>\n<strong>N N N R R N R R N R R N R<\/strong>","explanation":"Recall that average precision is calculated by scanning through the list of retrieved documents (in the order that they are reported) and computing the precision at every point that we retrieve a relevant document. We then get the Average Precision by averaging over those precisions. Also recall that precision in this context is the number of relevant documents retrieved so far divided by the number of documents retrieved so far.","option_groups":{"@attributes":{"randomize":"true"},"option_group":{"@attributes":{"select":"all"},"option":[{"@attributes":{"id":"bec515f8fefe8a1a91fa04a8031761de","selected_score":"0","unselected_score":"0"},"text":"$$0.342$$","explanation":"You may have calculated the precision at every point that a document is retrieved. However, you should only calculate the precision at the points when a relevant document is retrieved, and then report the average of those precisions."},{"@attributes":{"id":"c84b324003f9f7801375888f7b056dab","selected_score":"0","unselected_score":"0"},"text":"$$0.538$$","explanation":"You may have calculated the precision just at the last relevant document retrieved. You have to calculate the precision at every point that you retrieve a relevant document and then take the average of those precisions."},{"@attributes":{"id":"d2f65407fb385fb4122434aa0d63dedd","selected_score":"0","unselected_score":"0"},"text":"$$0.213$$","explanation":"You may have calculated the precision at every point that an irrelevant document is retrieved and taken the average of those precisions. You are supposed to calculate the precision at every point that a <em>relevant<\/em> document is retrieved and report the mean of those precisions."},{"@attributes":{"id":"6da389df568cfe6e9b651a71357e0b21","selected_score":"1","unselected_score":"0"},"text":"$$0.452$$","explanation":"Correct!"}]}}}},{"@attributes":{"id":"134f84227cbf342831b883baf3be3e5d","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"What is the average precision for the following sequence of retrieved documents, where <strong>R<\/strong> denotes a relevant document and <strong>N<\/strong> denotes an irrelevant document?\n<br \/><br \/>\n<strong>R R R R N N N N N N R N R<\/strong>","explanation":"Recall that average precision is calculated by scanning through the list of retrieved documents (in the order that they are reported) and computing the precision at every point that we retrieve a relevant document. We then get the Average Precision by averaging over those precisions. Also recall that precision in this context is the number of relevant documents retrieved so far divided by the number of documents retrieved so far.","option_groups":{"@attributes":{"randomize":"true"},"option_group":{"@attributes":{"select":"all"},"option":[{"@attributes":{"id":"a36c8bc9bf0bafb5e9dafa600f11168d","selected_score":"1","unselected_score":"0"},"text":"$$0.819$$","explanation":"Correct!"},{"@attributes":{"id":"7c644dbf22db4610c4a81b16a383764c","selected_score":"0","unselected_score":"0"},"text":"$$0.670$$","explanation":"You may have calculated the precision at every point that a document is retrieved. However, you should only calculate the precision at the points when a relevant document is retrieved, and then report the average of those precisions."},{"@attributes":{"id":"ba36bfabcce2f8da377b7bb2362f5f33","selected_score":"0","unselected_score":"0"},"text":"$$0.543$$","explanation":"You may have calculated the precision at every point that an irrelevant document is retrieved and taken the average of those precisions. You are supposed to calculate the precision at every point that a <em>relevant<\/em> document is retrieved and report the mean of those precisions."},{"@attributes":{"id":"fbe1498ae906070c83b37a17d60d168d","selected_score":"0","unselected_score":"0"},"text":"$$0.462$$","explanation":"You may have calculated the precision just at the last relevant document retrieved. You have to calculate the precision at every point that you retrieve a relevant document and then take the average of those precisions."}]}}}},{"@attributes":{"id":"585046969589bbd1b97191c0565004f4","type":"GS_Choice_Answer_Question"},"metadata":{"parameters":{"rescale_score":"1","choice_type":"radio"}},"data":{"text":"What is the average precision for the following sequence of retrieved documents, where <strong>R<\/strong> denotes a relevant document and <strong>N<\/strong> denotes an irrelevant document?\n<br \/><br \/>\n<strong>N R R N N N R R N N N N N N R<\/strong>","explanation":"Recall that average precision is calculated by scanning through the list of retrieved documents (in the order that they are reported) and computing the precision at every point that we retrieve a relevant document. We then get the Average Precision by averaging over those precisions. Also recall that precision in this context is the number of relevant documents retrieved so far divided by the number of documents retrieved so far.","option_groups":{"@attributes":{"randomize":"true"},"option_group":{"@attributes":{"select":"all"},"option":[{"@attributes":{"id":"70526c030f2990aac7f7fb798f558a4e","selected_score":"0","unselected_score":"0"},"text":"$$0.333$$","explanation":"You may have calculated the precision just at the last relevant document retrieved. You have to calculate the precision at every point that you retrieve a relevant document and then take the average of those precisions."},{"@attributes":{"id":"76dfe4010d7b82ef98e2a74fc73e2661","selected_score":"0","unselected_score":"0"},"text":"$$0.386$$","explanation":"You may have calculated the precision at every point that a document is retrieved. However, you should only calculate the precision at the points when a relevant document is retrieved, and then report the average of those precisions."},{"@attributes":{"id":"5f816f1c96fcb14a8af716ac5f5b3e01","selected_score":"1","unselected_score":"0"},"text":"$$0.486$$","explanation":"Correct!"},{"@attributes":{"id":"4a72cdd21553b140c000cf7cd4a5963a","selected_score":"0","unselected_score":"0"},"text":"$$0.337$$","explanation":"You may have calculated the precision at every point that an irrelevant document is retrieved and taken the average of those precisions. You are supposed to calculate the precision at every point that a <em>relevant<\/em> document is retrieved and report the mean of those precisions."}]}}}}]}]}}}